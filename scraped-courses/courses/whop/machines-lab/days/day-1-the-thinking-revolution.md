# Day 1 - The Thinking Revolution

## Module Overview
- **Chapters:** 2
- **Lessons:** 4
- **Theme:** Understanding why prompts fail and how to organize information effectively

---

## Chapter 1: Why Prompts Fail

### Lesson 1: Why Your Prompts Fail Before They Reach the AI

Hey.

So you've probably been writing prompts for a while now. Maybe you've collected some templates, bookmarked a few "amazing prompt libraries," tried copying what worked for someone else.

And sometimes it works... but most of the time it doesn't.

Here's what's actually happening.

#### The Real Problem (It's Not What You Think)

Most people think prompt engineering is about finding the magic words. Like there's some secret incantation that makes AI work better. "If I just use the right format..." or "Maybe I need more detailed instructions..." or "Let me try that prompt everyone's sharing on Twitter."

Wrong.

Your prompts are failing before the AI even sees them. The problem isn't in the AI's processing - it's in your thinking.

Here's the truth: you haven't actually decided what you want before you start typing.

Think about it... when was the last time you sat down and wrote a prompt knowing exactly what outcome you needed, exactly what the AI would need to deliver that outcome, and exactly how you'd recognize success when you saw it?

Probably never.

Most people approach prompting like this: "I need some marketing content. Let me ask AI to write marketing content. Hmm, this isn't quite right. Let me try again with more details."

That's not prompt engineering. That's hoping and iterating.

#### The Thinking That Changes Everything

Before you write a single word of any prompt, you need to answer three questions. And I mean really answer them, not just have a vague sense of what you want.

**Question 1: What specific outcome do I want?**

Not "write me an email." That's not specific. That's a category.

"Write a follow-up email to a potential client who showed interest in our SEO services three weeks ago, responded positively to our initial proposal, but hasn't replied to our last two check-ins."

See the difference? The first version gives the AI almost nothing to work with. The second version gives context, timeline, relationship status, and communication history.

**Question 2: What does the AI need to know to deliver that outcome?**

This is where most people completely fail. They assume the AI knows their business, their audience, their communication style, their constraints.

It doesn't.

If you want that follow-up email, the AI needs to know: your company's tone of voice, what the original proposal included, why this client matters, what kind of response you're hoping for, any deadline considerations, and probably a dozen other contextual details you take for granted.

**Question 3: How will I know if the output is good?**

This might be the most important question, and almost nobody asks it.

You can't evaluate a prompt's success if you haven't defined what success looks like. "Sounds professional" isn't success criteria. "Maintains friendly but persistent tone, references specific proposal elements, includes clear next step, and feels personally written rather than templated" - that's success criteria.

#### Let's See This in Action

Here's a prompt I see constantly:

*"Write a professional email to a client about project delays."*

What's wrong with this? Everything. Let's think through our three questions:

**What specific outcome?** We don't know what kind of delay, what kind of client, what kind of project, what the relationship is like, whether this is the first delay or the fifth.

**What does AI need to know?** Client personality, project details, reason for delay, company communication style, previous communications, urgency level, proposed solutions.

**Success criteria?** No clue what "professional" means in this context.

Now watch what happens when we think first:

*"Write an email to Emmy, our long-term client who's been working with us for two years on quarterly marketing campaigns. We need to inform her that our current campaign launch will be delayed by one week due to a technical issue with the landing page integration. Emmy appreciates direct communication and detailed explanations. The tone should be apologetic but confident, include a specific new timeline, and offer a small compensation for the inconvenience. Keep it under 150 words."*

That's the same request, but now the AI actually has something to work with.

#### Your First Reality Check

Before we practice this, let me tell you something that might be uncomfortable.

Most of your prompt "failures" aren't failures at all. The AI is working perfectly - it's giving you exactly what you asked for based on the vague, contextless instructions you provided.

When you say "write professional content" and get generic, boring output... that's not the AI failing. That's the AI succeeding at an impossible task with insufficient information.

This realization changes everything about how you approach prompting.

**Practice Exercise:** Use the prompt "PROMPT 1 - Prompt Analyst" to work through analyzing these three terrible examples. The AI will guide you through discovering why they fail, but you'll be doing the thinking work yourself.

#### The Breakthrough Moment

Here's when you know you're getting it: you start spending more time thinking about your prompt than writing it.

Most people spend 30 seconds writing a prompt and 30 minutes iterating on bad results. Expert prompt engineers spend 5 minutes thinking through their request and get the result they want on the first try.

This thinking framework is just the foundation. Once you master this basic approach, you can start building systematic prompt architectures, designing multi-step workflows, and creating automated systems that scale this thinking across entire business processes... but that's way beyond foundation level.

For now, focus on training your brain to think before you type.

Tomorrow, we'll get into how to organize all that thinking into context that actually helps the AI understand what you need.

**Your Assignment:** Document three prompts you've used recently that didn't work well. Apply the three-question framework to each one. Don't fix them yet - just identify where your thinking was unclear. Save these in your workspace because we'll use them throughout the week.

The goal isn't to write better prompts yet. The goal is to recognize unclear thinking when you see it.

That's the real foundation of prompt engineering.

---

### Lesson 2: Prompt 1 - Prompt Analyst

**COPY + PASTE INSIDE YOUR LLM**

Link: https://machina.notion.site/Prompt-1-Prompt-Analyst-269c6b3f876980cb956acf867f305d91?source=copy_link

```
<role>

You are a masterful prompt engineering coach who specializes in developing analytical thinking through guided self-discovery. Rather than lecturing, you create "aha moments" by asking precisely the right questions at the right time. You understand that true learning happens when students uncover insights themselves, not when they're told what to think.

</role>

<teaching_philosophy>

- Discovery over Direction: You guide students to revelations rather than giving answers

- One Question at a Time: You ask a single, powerful question that opens up thinking, then wait for their response before proceeding

- Build on Their Words: You use the student's own language and examples to deepen their understanding

- Create Cognitive Tension: You help them feel the gap between what they know and what they need to know

</teaching_philosophy>

<context>

I'm learning prompt engineering through a three-question analysis framework:

1. Outcome Clarity: What specific outcome do I want?

2. Context Completeness: What does the AI need to know to deliver that outcome?

3. Success Criteria: How will I know if the output is good?

I'll provide you with three flawed prompts that would produce generic, unhelpful results:

1. "Create a social media post about productivity"

2. "Write a report on market trends"

3. "Make a presentation about our company"

</context>

<discovery_process>

For each prompt, instead of explaining what's wrong:

Initial Engagement: Start by asking me to imagine I'm the AI receiving this prompt. What questions would immediately pop into my mind? Let me experience the confusion firsthand.

Guided Analysis: Use questions that help me discover:

- What assumptions am I making that the AI can't possibly know?

- What would ten different AIs produce with this same prompt, and why would they all be different?

- What's the gap between what I'm asking for and what I actually need?

Self-Discovery Moments: Guide me to realize:

- The difference between a task and an outcome

- Why context isn't just helpful—it's essential for quality

- How vague success criteria guarantee disappointing results

</discovery_process>

<natural_flow_rules>

- Never give away the insight - let me discover it

- Ask only one question at a time - give me space to think

- Build on my responses - use my words to go deeper

- Stay curious, not corrective - approach this as genuine exploration together

</natural_flow_rules>

<success_indicators>

You'll know this is working when:

- I start asking better questions myself

- I begin noticing problems before you point them out

- I connect insights across different prompt examples

- I feel excited about the discovery process rather than defensive

</success_indicators>

<task>

Begin with the first prompt: "Create a social media post about productivity"

Ask me the one question that will help me feel what it's like to be an AI receiving this instruction. Make me experience the uncertainty firsthand.

</task>
```

---

## Chapter 2: Context Architecture

### Lesson 3: The Context Architecture

So you've figured out the thinking part. You know what you want, you've identified what the AI needs to know, and you've defined success criteria.

Now comes the question that stumps most people: how do you actually organize all that information so the AI processes it the way you intend?

Right now i'm guessing you just dump everything into a paragraph and hope for the best…

There's a better way.

#### Your AI Isn't Reading Like a Human

Here's something you probably don't realize: AI doesn't process your prompt the way you read a book. It doesn't skim, doesn't jump around, doesn't "get the gist" and fill in gaps from experience.

It processes information sequentially, token by token, building understanding as it goes. The information you put first literally shapes how it interprets everything that comes after.

Think of it like this... if you're giving someone directions, you don't start with "turn left at the blue house" without first telling them what street they're on and where they're headed. The AI needs that same logical information flow.

But here's where most people mess up. They organize their prompts the way they think about the problem, not the way the AI needs to process the solution.

#### The Simple Architecture That Changes Everything

After running thousands of prompts for my agencies, I've found that information works best in this order:

**Layer 1: Critical Context (Goes First)**
The stuff the AI absolutely must know to understand the task. Your role, the situation, the constraints that can't be negotiated.

**Layer 2: Supporting Details (Goes Middle)**
Background information, examples, additional context that helps but isn't make-or-break.

**Layer 3: Specific Instructions (Goes Last)**
What you want done, how you want it formatted, what the output should look like.

Why this order? Because each layer builds the foundation for the next. The AI uses Layer 1 to establish its approach, Layer 2 to refine its understanding, and Layer 3 to execute with precision.

#### Let's See This in Action

Here's a prompt organized the wrong way:

> *"Write a 300-word blog post about email marketing best practices in a professional but conversational tone. I run a marketing agency that helps small businesses. The post should include actionable tips and avoid technical jargon. Our audience is small business owners who are new to email marketing."*

What's wrong? The instruction comes first, then context gets scattered throughout. The AI has to constantly revise its approach as new context appears.

Now watch the same information organized properly:

> *"You are a marketing consultant writing for small business owners who are new to email marketing. I run a marketing agency focused on practical, jargon-free advice for businesses just getting started with digital marketing. Our audience values actionable tips over theory.*
>
> *Background: Most small business owners know they "should" do email marketing but feel overwhelmed by all the technical advice online. They need simple, proven strategies they can implement immediately.*
>
> *Task: Write a 300-word blog post about email marketing best practices. Use a professional but conversational tone. Focus on actionable tips. Avoid technical jargon."*

Same information, completely different organization. The AI now understands who it is, who it's writing for, and what problem it's solving before it starts thinking about the specific task.

#### The Critical Context Test

Not sure what counts as "critical context"? Ask yourself: if the AI only knew this one piece of information, would it fundamentally change how it approaches the entire task?

If yes, that's critical context. Goes first.

If it would just refine or improve the output, that's supporting detail. Goes middle.

If it's about format or specific requirements, that's instruction. Goes last.

Here's the thing though... this is just the foundation level of context architecture. Once you understand this basic layering, you can start building sophisticated information hierarchies, dynamic context systems, and multi-dimensional context mapping that most people never even know exists.

There are advanced practitioners building context workflows that automatically adapt based on the type of request, chain context across multiple interactions, and create self-optimizing information architectures... but that's way beyond what we're covering here.

For now, master this simple three-layer approach.

**Practice Exercise:** Use the prompt "Prompt 2 - Context Practice" to practice organizing information into the three-layer architecture. The AI will guide you through identifying what belongs where, but you'll be doing the analytical work.

#### Why This Actually Matters

Getting the architecture right means the difference between AI that understands your request and AI that's constantly course-correcting as it discovers new context.

When you nail the information flow, you get outputs that feel like they came from someone who truly understood the assignment from the beginning.

When you get it wrong, you get outputs that feel... off. Like the AI was guessing about important details and hoping for the best.

#### The Foundation You're Building

This simple three-layer approach is your foundation for context engineering. Once this becomes second nature, you can start exploring advanced techniques like contextual priming, information weighting, dynamic context adaptation, and architectural optimization that can transform how AI responds to complex requests.

But first, master the basics.

Tomorrow, we'll dive into how to make your instructions so clear that the AI can't possibly misunderstand what you want.

**Your Assignment:** Take one of the prompts you analyzed yesterday (the ones that didn't work well). Practice reorganizing the information using the three-layer architecture. Don't test it yet - just focus on organizing the information flow. Document the before and after in your workspace.

Notice how reorganizing the same information changes how clear the request feels, even to you.

---

### Lesson 4: Prompt 2 - Context Practice

**COPY + PASTE THIS PROMPT IN YOUR LLM**

Link: https://machina.notion.site/Prompt-2-Prompt-2-Context-Practice-269c6b3f876980b5a6aff20243d540c9?source=copy_link

```
<role>

You are a master prompt engineering workshop facilitator with 15+ years of experience training professionals. You specialize in hands-on, experiential learning that builds muscle memory through deliberate practice. You create challenging but achievable learning experiences where students discover principles through guided application rather than passive instruction.

</role>

<workshop_philosophy>

- Practice Over Theory: Students learn by doing, not by being told

- Progressive Complexity: Each scenario builds skills needed for the next level

- Active Discovery: You ask questions that force critical thinking rather than giving answers

- Mastery Confirmation: No progression until current skills are demonstrated

- Real-World Application: Every exercise mirrors actual professional challenges

</workshop_philosophy>

<learning_architecture>

Students must master the three-layer information organization:

1. Critical Context: What the AI absolutely must know to succeed

2. Supporting Details: Information that improves quality and accuracy

3. Specific Instructions: Precise directions for format, tone, and execution

Students apply the three-question thinking framework:

1. What specific outcome do I want?

2. What does the AI need to know to deliver that outcome?

3. How will I know if the output is good?

</learning_architecture>

<workshop_structure>

Five Progressive Scenarios:

1. Simple Business Email (Foundation skills)

2. Content Creation (Audience and purpose clarity)

3. Problem-Solving (Analytical thinking and constraints)

4. Creative/Strategic (Balancing creativity with business objectives)

5. Complex Multi-Stakeholder (Managing competing priorities and contexts)

Each scenario includes:

- Poorly written original prompt (realistic beginner mistakes)

- Complete background context for improvement

- Clear success criteria for evaluation

- Guided improvement process with probing questions

</workshop_structure>

<facilitation_methodology>

For each scenario:

1. Present the flawed prompt and context

2. Ask diagnostic questions to identify specific problems

3. Guide application of the three-question framework

4. Coach organization of information into three layers

5. Facilitate rewriting with targeted questions

6. Provide feedback and refinement until mastery is demonstrated

7. Confirm understanding before advancing

Never provide solutions directly - always guide discovery through strategic questioning.

</facilitation_methodology>

<workshop_progression_rules>

- No advancement until current scenario is mastered

- Use student's own language and insights to build deeper understanding

- Create productive struggle - challenge without overwhelming

- Celebrate breakthroughs and connect insights across scenarios

- Build confidence through demonstrated competence

</workshop_progression_rules>

<mastery_validation>

Student demonstrates readiness to advance when they:

- Identify prompt problems without prompting

- Apply frameworks automatically

- Organize information logically before writing

- Write clear, specific instructions

- Articulate why their improved version will work better

</mastery_validation>

<task>

SCENARIO 1: Simple Business Email

Here's a poorly written prompt a beginner might create:

"Write an email to my team about the new project timeline changes."

Background Context You Have:

- Your team of 8 people has been working on a software development project

- Original deadline was March 15th, now pushed to April 30th due to client scope changes

- Some team members have been working overtime and are frustrated

- You need to maintain morale while being transparent about the changes

- The client added three new features that require additional development time

- You're the project manager and need to sound decisive but empathetic

Success Criteria:

- Team understands the timeline change and reasons

- Morale remains positive despite the setback

- Clear next steps are communicated

- Professional tone that acknowledges their hard work

Now, before we work on improving this prompt, I need you to put on your detective hat.

What's the most glaring problem you see when you imagine an AI trying to fulfill this original prompt?

Think about it from the AI's perspective - what critical information is completely missing that would leave it guessing?

</task>
```

---

## Resources

| Title | URL | Type |
|-------|-----|------|
| Prompt 1 - Prompt Analyst | https://machina.notion.site/Prompt-1-Prompt-Analyst-269c6b3f876980cb956acf867f305d91 | Notion |
| Prompt 2 - Context Practice | https://machina.notion.site/Prompt-2-Prompt-2-Context-Practice-269c6b3f876980b5a6aff20243d540c9 | Notion |

---

## Key Takeaways

1. **The Three-Question Framework:**
   - What specific outcome do I want?
   - What does the AI need to know to deliver that outcome?
   - How will I know if the output is good?

2. **The Three-Layer Architecture:**
   - Layer 1 (First): Critical Context - what AI must know
   - Layer 2 (Middle): Supporting Details - background that helps
   - Layer 3 (Last): Specific Instructions - format and requirements

3. **Core Insight:** Your prompts fail before the AI sees them - the problem is in your thinking, not the AI's processing.
